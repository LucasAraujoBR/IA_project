{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffe040c",
   "metadata": {},
   "source": [
    "Link dos datasets\n",
    "\n",
    "Samba: https://www.kaggle.com/datasets/clovesgtx/brazilian-music-samba-lyrics\n",
    "\n",
    "Gospel: https://raw.githubusercontent.com/damarals/letras/master/inst/csv/letras.csv\n",
    "\n",
    "Axe: https://www.kaggle.com/datasets/jorgefjr/brazilian-songs-lyrics\n",
    "\n",
    "Funk: https://www.kaggle.com/datasets/sleshes/funk-carioca-dataset\n",
    "\n",
    "Bossa Nova: https://www.kaggle.com/datasets/mcarujo/bossa-nova-lyrics\n",
    "\n",
    "Rock,Sertanejo, Samba2 = https://github.com/gabriellmd/data-frames-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc065807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf7cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa = pd.read_csv('datasets/bossa_nova_songs_dataset.csv')\n",
    "samba2 = pd.read_csv('datasets/musicas_samba.csv')\n",
    "sertanejo = pd.read_csv('datasets/musicas_sertanejo.csv')\n",
    "samba = pd.read_csv('datasets/samba_dataset.csv',sep='|')\n",
    "axe = pd.read_csv('datasets/letras_mus_br_axe.csv')\n",
    "funk = pd.read_csv('datasets/Dataset_funk_carioca.csv')\n",
    "rock = pd.read_csv('datasets/musicas_rock.csv') \n",
    "gospel = pd.read_csv('datasets/gospel.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1497972",
   "metadata": {},
   "source": [
    "Padronização dos datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ffe141",
   "metadata": {},
   "outputs": [],
   "source": [
    "gospel_ajustado = pd.DataFrame(gospel['letra'])  #OK\n",
    "gospel_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c493a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_ajustado = pd.DataFrame(rock['Lyric'])  #OK\n",
    "rock_ajustado.rename(columns={'Lyric': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb4247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samba_ajustado = pd.DataFrame(samba['letra'])  #OK\n",
    "samba_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "samba2_ajustado = pd.DataFrame(samba2['Lyric'])  #OK\n",
    "samba2_ajustado.rename(columns={'Lyric': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a8c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "axe_ajustado = pd.DataFrame(axe['letras'])  #OK\n",
    "axe_ajustado.rename(columns={'letras': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dbdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "funk_ajustado = pd.DataFrame(funk['letra'])  #OK\n",
    "funk_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee6dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa_ajustado = pd.DataFrame(bossa['song_lyrics'])  #OK\n",
    "bossa_ajustado.rename(columns={'song_lyrics': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec3251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sertanejo_ajustado = pd.DataFrame(sertanejo['Lyric'])  #OK\n",
    "sertanejo_ajustado.rename(columns={'Lyric': 'lyric'}, inplace = True) #OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846236d5",
   "metadata": {},
   "source": [
    "Criando a coluna correspondete ao genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5388e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa_ajustado['gen'] = 'Bossa Nova'\n",
    "funk_ajustado['gen'] = 'Funk'\n",
    "gospel_ajustado['gen'] = 'Gospel'\n",
    "sertanejo_ajustado['gen'] = 'Sertanejo'\n",
    "axe_ajustado['gen'] = 'Axe'\n",
    "rock_ajustado['gen'] = 'Rock'\n",
    "samba_ajustado['gen'] = 'Samba'\n",
    "samba2_ajustado['gen'] = 'Samba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171d7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [bossa_ajustado,funk_ajustado,gospel_ajustado,sertanejo_ajustado,axe_ajustado,rock_ajustado,samba_ajustado,samba2_ajustado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb1cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea7bfd",
   "metadata": {},
   "source": [
    "# Dataset final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "461bea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De tudo, ao meu amor serei atento antes E co...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Era uma casa Muito engraçada Não tinha teto ...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E por falar em saudade Onde anda você Onde a...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filhos... Filhos? Melhor não tê-los! Mas se ...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>É melhor ser alegre que ser triste Alegria é...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65762</th>\n",
       "      <td>Tom............:. Introdução.: Dm C#o Gm C7 F ...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65763</th>\n",
       "      <td>Resolvi te abandonar te deixar para traz, deci...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65764</th>\n",
       "      <td>Ela mexe comigo. E o pior que não sabe. Coment...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65765</th>\n",
       "      <td>O pai me disse que a tradição é lanterna. Vem ...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65766</th>\n",
       "      <td>O Sonho Não Acabou / Vivo Isolado do Mundo (DV...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lyric         gen\n",
       "0        De tudo, ao meu amor serei atento antes E co...  Bossa Nova\n",
       "1        Era uma casa Muito engraçada Não tinha teto ...  Bossa Nova\n",
       "2        E por falar em saudade Onde anda você Onde a...  Bossa Nova\n",
       "3        Filhos... Filhos? Melhor não tê-los! Mas se ...  Bossa Nova\n",
       "4        É melhor ser alegre que ser triste Alegria é...  Bossa Nova\n",
       "...                                                  ...         ...\n",
       "65762  Tom............:. Introdução.: Dm C#o Gm C7 F ...       Samba\n",
       "65763  Resolvi te abandonar te deixar para traz, deci...       Samba\n",
       "65764  Ela mexe comigo. E o pior que não sabe. Coment...       Samba\n",
       "65765  O pai me disse que a tradição é lanterna. Vem ...       Samba\n",
       "65766  O Sonho Não Acabou / Vivo Isolado do Mundo (DV...       Samba\n",
       "\n",
       "[65767 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.reset_index(drop=True,inplace=True)\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157820a",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d2108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_texto(txt):\n",
    "    # remover quebras de linha\n",
    "    txt = txt.replace('\\n',' ')\n",
    "    # remover símbolos de pontuação, resultando em um array de caracteres\n",
    "    txt = [char for char in txt if char not in string.punctuation]\n",
    "    # depois, juntar os caracteres em palavras novamente e separá-los em uma lista de tokens\n",
    "    txt = ''.join(txt).split()\n",
    "    # por fim, remover as stopwords da lista\n",
    "    #txt = [word for word in txt if word.lower() not in stopwords.words('portuguese')]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608499e",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d765f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_array = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659be4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomF:\n",
      "fit RF\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "n = '\\nNaiveB:'\n",
    "r = '\\nRandomF:'\n",
    "all_scores = {'NaiveBayes': [], 'RandomForest': []}\n",
    "for count in range(5):\n",
    "    lyric_train,lyric_test,gen_train,gen_test = train_test_split(lyrics['lyric'],lyrics['gen'],test_size=0.3)\n",
    "    #naiveB = Pipeline([\n",
    "    #('bow',CountVectorizer(analyzer=processamento_texto,encoding ='unicode')),\n",
    "    #('tfidf',TfidfTransformer()),\n",
    "    #('nb',MultinomialNB())\n",
    "    #])\n",
    "    #print(n)\n",
    "    randomF = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto,encoding ='unicode')),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('rf',RandomForestClassifier())\n",
    "    ])\n",
    "    print(r)\n",
    "    #naiveB.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))\n",
    "    #print('fit NB')\n",
    "    randomF.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))\n",
    "    print('fit RF')\n",
    "    scoring = {'acc': 'accuracy'}\n",
    "    #scoresNB = cross_validate(naiveB,lyrics['lyric'].values.astype('U'),lyrics['gen'].values.astype('U'),cv=10,scoring=scoring)\n",
    "    scoresRF = cross_validate(randomF,lyrics['lyric'].values.astype('U'),lyrics['gen'].values.astype('U'),cv=10,scoring=scoring)\n",
    "    print('score:')\n",
    "    #print(scoresNB)\n",
    "    #print(r)\n",
    "    print(scoresRF)\n",
    "    #all_scores['NaiveBayes'].append(scoresNB)\n",
    "    all_scores['RandomForest'].append(scoresRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bcd390",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1169a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d39204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034fe3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"def convert(data):\n",
    "    number = preprocessing.LabelEncoder()\n",
    "    data['lyric'] = number.fit_transform(data.lyric)\n",
    "    #data['gen'] = number.fit_transform(data.gen)\n",
    "    data=data.fillna(-999)\n",
    "    return data\n",
    "\n",
    "lyric_train.column #= convert(lyric_train)\n",
    "#gen_train = convert(gen_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7425d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train=convert(train)\n",
    "#test=convert(test)\n",
    "#pipeline_2.fit(lyric_train,gen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31158481",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_2.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = pipeline_2.predict(lyric_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdee9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gen_test,predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bff173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
