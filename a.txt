### Expressões regulares
import re
### Stopwords
import nltk
### Lematização
import spacy


spc_pt = spacy.load("pt_core_news_sm")

def limpar_texto(texto):

  # Remover caracteres que não são letras e tokenização
    letras =  re.findall(r'\b[A-zÀ-úü]+\b', texto.lower())

    #Remover stopwords
    stopwords = nltk.corpus.stopwords.words('portuguese')
    #Adicionando stopwords que não estão na lista do nltk 
    stopwords.append("'")
    stopwords.append("pra")
    stopwords.append("tá")
    stop = set(stopwords)

    meaningful_words = [w for w in letras if w not in stopwords]
    meaningful_words_string = " ".join(meaningful_words)

    #Instanciando o objeto spacy
    spc_letras =  spc_pt(meaningful_words_string)

    #Lemmização 
    tokens = [token.lemma_ if token.pos_ == 'VERB' else str(token) for token in spc_letras]

    #problemas com verbo ir
    ir = ['vou', 'vais', 'vai', 'vamos', 'ides', 'vão']
    tokens = ['ir' if token in ir else str(token) for token in tokens]

    return tokens 