{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f839a700",
   "metadata": {},
   "source": [
    "Link dos datasets\n",
    "\n",
    "Samba: https://www.kaggle.com/datasets/clovesgtx/brazilian-music-samba-lyrics\n",
    "\n",
    "Gospel: https://raw.githubusercontent.com/damarals/letras/master/inst/csv/letras.csv\n",
    "\n",
    "Axe: https://www.kaggle.com/datasets/jorgefjr/brazilian-songs-lyrics\n",
    "\n",
    "Funk: https://www.kaggle.com/datasets/sleshes/funk-carioca-dataset\n",
    "\n",
    "Bossa Nova: https://www.kaggle.com/datasets/mcarujo/bossa-nova-lyrics\n",
    "\n",
    "Rock,Sertanejo, Samba2 = https://github.com/gabriellmd/data-frames-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10778778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1df1e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa = pd.read_csv('datasets/bossa_nova_songs_dataset.csv')\n",
    "samba = pd.read_csv('datasets/samba_dataset.csv',sep='|')\n",
    "axe = pd.read_csv('datasets/letras_mus_br_axe.csv')\n",
    "funk = pd.read_csv('datasets/Dataset_funk_carioca.csv')\n",
    "gospel = pd.read_csv('datasets/gospel.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "517c6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gospel_ajustado = pd.DataFrame(gospel['letra'])  #OK 55000\n",
    "gospel_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK\n",
    "gospel_ajustado.drop(gospel_ajustado.tail(51498).index,inplace = True) #3000\n",
    "samba_ajustado = pd.DataFrame(samba['letra'])  #OK 3000\n",
    "samba_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK\n",
    "samba_ajustado.drop(samba_ajustado.tail(118).index,inplace = True) #3000\n",
    "axe_ajustado = pd.DataFrame(axe['letras'])  #OK1000\n",
    "axe_ajustado.rename(columns={'letras': 'lyric'}, inplace = True) #OK\n",
    "funk_ajustado = pd.DataFrame(funk['letra'])  #OK 1000\n",
    "funk_ajustado.rename(columns={'letra': 'lyric'}, inplace = True) #OK\n",
    "bossa_ajustado = pd.DataFrame(bossa['song_lyrics'])  #OK 6000\n",
    "bossa_ajustado.rename(columns={'song_lyrics': 'lyric'}, inplace = True) #OK\n",
    "bossa_ajustado.drop(bossa_ajustado.tail(3106).index,inplace = True) #3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ba233b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bossa_ajustado['gen'] = 'Bossa Nova'\n",
    "funk_ajustado['gen'] = 'Funk'\n",
    "gospel_ajustado['gen'] = 'Gospel'\n",
    "axe_ajustado['gen'] = 'Axe'\n",
    "samba_ajustado['gen'] = 'Samba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39c5af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [bossa_ajustado,funk_ajustado,bossa_ajustado,axe_ajustado,samba_ajustado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1413bfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De tudo, ao meu amor serei atento antes E co...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Era uma casa Muito engraçada Não tinha teto ...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E por falar em saudade Onde anda você Onde a...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filhos... Filhos? Melhor não tê-los! Mas se ...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>É melhor ser alegre que ser triste Alegria é...</td>\n",
       "      <td>Bossa Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>( Não tenho lar Não tenho amor Pra que vou me ...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>o  Senhor é a minha forçao meu escudo...minha ...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>Sorte é sorte o malandro também tem seu dia d...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>A gente briga sem querer Chora \"prá\" voltar F...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>Aprendeu-se a liberdade Combatendo em  Guarar...</td>\n",
       "      <td>Samba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lyric         gen\n",
       "0        De tudo, ao meu amor serei atento antes E co...  Bossa Nova\n",
       "1        Era uma casa Muito engraçada Não tinha teto ...  Bossa Nova\n",
       "2        E por falar em saudade Onde anda você Onde a...  Bossa Nova\n",
       "3        Filhos... Filhos? Melhor não tê-los! Mas se ...  Bossa Nova\n",
       "4        É melhor ser alegre que ser triste Alegria é...  Bossa Nova\n",
       "...                                                  ...         ...\n",
       "10995  ( Não tenho lar Não tenho amor Pra que vou me ...       Samba\n",
       "10996  o  Senhor é a minha forçao meu escudo...minha ...       Samba\n",
       "10997   Sorte é sorte o malandro também tem seu dia d...       Samba\n",
       "10998   A gente briga sem querer Chora \"prá\" voltar F...       Samba\n",
       "10999   Aprendeu-se a liberdade Combatendo em  Guarar...       Samba\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = pd.concat(datasets)\n",
    "lyrics.reset_index(drop=True,inplace=True)\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "929f8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processamento_texto(txt):\n",
    "    # remover quebras de linha\n",
    "    txt = txt.replace('\\n',' ')\n",
    "    # remover símbolos de pontuação, resultando em um array de caracteres\n",
    "    txt = [char for char in txt if char not in string.punctuation]\n",
    "    # depois, juntar os caracteres em palavras novamente e separá-los em uma lista de tokens\n",
    "    txt = ''.join(txt).split()\n",
    "    # por fim, remover as stopwords da lista\n",
    "    #txt = [word for word in txt if word.lower() not in stopwords.words('portuguese')]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8963a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg ={'SVM':{\n",
    "    'fit_time':np.array([]),\n",
    "    'score_time':np.array([]),\n",
    "    'test_accuracy':np.array([]),\n",
    "    'test_f1_score':np.array([]),\n",
    "},\n",
    "     'RF':{\n",
    "    'fit_time':np.array([]),\n",
    "    'score_time':np.array([]),\n",
    "    'test_accuracy':np.array([]),\n",
    "    'test_f1_score':np.array([]),\n",
    "},\n",
    "     'NB':{\n",
    "    'fit_time':np.array([]),\n",
    "    'score_time':np.array([]),\n",
    "    'test_accuracy':np.array([]),\n",
    "    'test_f1_score':np.array([]),\n",
    "} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33322515",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(5):\n",
    "    #aleatorio\n",
    "    lyric_train,lyric_test,gen_train,gen_test = train_test_split(lyrics['lyric'],lyrics['gen'],test_size=0.3)\n",
    "    #dados SVC\n",
    "    pipeline_svc = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto,encoding ='unicode')),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('svc',SVC())\n",
    "    ])\n",
    "    #dados NB\n",
    "    pipeline_nb = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto,encoding ='unicode')),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('nb',MultinomialNB())\n",
    "    ])\n",
    "    #dadps RF\n",
    "    pipeline_rf = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=processamento_texto,encoding ='unicode')),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('rf',RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    #Etapa de Fit\n",
    "    pipeline_svc.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))\n",
    "    pipeline_nb.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))\n",
    "    pipeline_rf.fit(lyric_train.values.astype('U'),gen_train.values.astype('U'))\n",
    "    \n",
    "    #Etapa 10-fold cross validation\n",
    "    scoring = {'accuracy' : 'accuracy', 'f1_score' : 'f1_micro'}\n",
    "    scores_svc = cross_validate(pipeline_svc,lyrics['lyric'].values.astype('U'),lyrics['gen'].values.astype('U'),cv=10,scoring=scoring)\n",
    "    scores_nb = cross_validate(pipeline_nb,lyrics['lyric'].values.astype('U'),lyrics['gen'].values.astype('U'),cv=10,scoring=scoring)\n",
    "    scores_rf = cross_validate(pipeline_rf,lyrics['lyric'].values.astype('U'),lyrics['gen'].values.astype('U'),cv=10,scoring=scoring)\n",
    "    \n",
    "    #Aninhamento de médias\n",
    "    #SVM\n",
    "    alg['SVM']['fit_time'] = np.append(alg['SVM']['fit_time'], scores_svm['fit_time'].mean())\n",
    "    alg['SVM']['score_time'] = np.append(alg['SVM']['score_time'], scores_svm['score_time'].mean())\n",
    "    alg['SVM']['test_accuracy'] = np.append(alg['SVM']['test_accuracy'], scores_svm['test_accuracy'].mean())\n",
    "    alg['SVM']['test_f1_score'] = np.append(alg['SVM']['test_f1_score'], scores_svm['test_f1_score'].mean())\n",
    "    #NB\n",
    "    alg['NB']['fit_time'] = np.append(alg['NB']['fit_time'], scores_nb['fit_time'].mean())\n",
    "    alg['NB']['score_time'] = np.append(alg['NB']['score_time'], scores_nb['score_time'].mean())\n",
    "    alg['NB']['test_accuracy'] = np.append(alg['NB']['test_accuracy'], scores_nb['test_accuracy'].mean())\n",
    "    alg['NB']['test_f1_score'] = np.append(alg['NB']['test_f1_score'], scores_nb['test_f1_score'].mean())\n",
    "    #RF\n",
    "    alg['RF']['fit_time'] = np.append(alg['RF']['fit_time'], scores_rf['fit_time'].mean())\n",
    "    alg['RF']['score_time'] = np.append(alg['RF']['score_time'], scores_rf['score_time'].mean())\n",
    "    alg['RF']['test_accuracy'] = np.append(alg['RF']['test_accuracy'], scores_rf['test_accuracy'].mean())\n",
    "    alg['RF']['test_f1_score'] = np.append(alg['RF']['test_f1_score'], scores_rf['test_f1_score'].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a330deac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85.2930145 , 86.02140307, 84.9799845 , 85.01941352, 86.04448705])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg['RF']['fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a765cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27017698, 0.26408484, 0.25601187, 0.29369226, 0.28299279])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg['RF']['score_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f5eec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43malg\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alg' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65737c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
